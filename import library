import numpy as np
import pandas as pd
import spacy
import string
import gensim
import operator
import re
#5 agustos eski kodlari yok say
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import re # regular expression libary.
import nltk # Natural Language toolkit
from nltk.corpus import stopwords
import seaborn as sns 

nltk.download("stopwords")  #downloading stopwords
nltk.download('punkt')
from nltk import word_tokenize,sent_tokenize
nltk.download('wordnet')
import nltk as nlp
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences 
from sklearn.feature_extraction.text import CountVectorizer 
from wordcloud import WordCloud 
from sklearn.feature_extraction.text import CountVectorizer #Bag of Words
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,precision_score
from sklearn import preprocessing
import warnings
warnings.filterwarnings("ignore")
import nltk
nltk.download('omw-1.4')

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/kanunum-nlp-doc-analysis-dataset.csv")
df_copy=df.copy()
df_copy.head()


sns.countplot("kategori",data=df_copy)

le = preprocessing.LabelEncoder()
labels=le.fit_transform(df_copy.kategori)
labels
nltk.download("stopwords")

baslik_list=[]

for baslik in df_copy.baslik:
    baslik = baslik.lower()  #Büyük harften -Küçük harfe çevirme
    baslik = re.sub("[^abcçdefgğhıijklmnoöprsştuüvyz]"," ",baslik)
    baslik=nltk.word_tokenize(baslik) # splits the words that are in the sentence from each other.
    baslik =[word for word in baslik if not word in set(stopwords.words("turkish"))]
    lemma=nlp.WordNetLemmatizer()
    baslik=[lemma.lemmatize(word) for word in baslik] # this code finds the root of the word for a word in the sentence and change them to their root form.
    baslik=" ".join(baslik)
    baslik_list.append(baslik) # store sentences in list

len(baslik_list)    


max_features=500 # "number" most common(used) words in reviews

count_vectorizer=CountVectorizer(max_features=max_features) 

sparce_matrix=count_vectorizer.fit_transform(baslik_list).toarray()
sparce_matrix.shape
sparce_matrix[0:10,0:20]
print("Top {} the most used word by reviewers: {}".format(max_features,count_vectorizer.get_feature_names()))

